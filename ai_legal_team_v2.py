"""
AI æ³•å¾‹æ–‡æ¡£åˆ†æåŠ©æ‰‹ - ä¸»åº”ç”¨
é›†æˆæ··åˆæ£€ç´¢ã€å¤šæ™ºèƒ½ä½“å®¡æŸ¥å’Œç»“æ„åŒ–æŠ¥å‘Šç”Ÿæˆ
"""

import streamlit as st
import os
import tempfile
from pathlib import Path
from typing import Optional, List
import asyncio

# Agno æ¡†æ¶
from agno.agent import Agent
from agno.team import Team
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.qdrant import Qdrant
from agno.models.openai import OpenAIChat
from agno.knowledge.embedder.openai import OpenAIEmbedder

# æ–°æ¶æ„ç»„ä»¶
from src.config.app_config import get_app_config
from src.retrieval.hybrid_search import create_hybrid_search_engine
from src.retrieval.bm25_indexer import BM25Indexer
from src.orchestration.review_pipeline import create_review_pipeline
from src.ui.display import display_report

from src.models.report_schema import LegalDocumentReport, DocumentType
from src.core.exceptions import ErrorHandler
from src.core.metrics import get_metrics_collector, init_metrics

# é…ç½®
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://api.zhizengzeng.com/v1")
COLLECTION_NAME = "legal_documents"


def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    # API Keys
    if 'openai_api_key' not in st.session_state:
        st.session_state.openai_api_key = None
    if 'qdrant_api_key' not in st.session_state:
        st.session_state.qdrant_api_key = None
    if 'qdrant_url' not in st.session_state:
        st.session_state.qdrant_url = None

    # æ•°æ®åº“å’Œå›¢é˜Ÿ
    if 'vector_db' not in st.session_state:
        st.session_state.vector_db = None
    if 'legal_team' not in st.session_state:
        st.session_state.legal_team = None
    if 'knowledge_base' not in st.session_state:
        st.session_state.knowledge_base = None

    # æ–°æ¶æ„ç»„ä»¶
    if 'hybrid_engine' not in st.session_state:
        st.session_state.hybrid_engine = None
    if 'review_pipeline' not in st.session_state:
        st.session_state.review_pipeline = None

    # é”™è¯¯å¤„ç†å’Œç›‘æ§
    if 'error_handler' not in st.session_state:
        st.session_state.error_handler = ErrorHandler()
    if 'metrics' not in st.session_state:
        st.session_state.metrics = get_metrics_collector(
            enabled=True,
            port=8000
        )

    # å·²å¤„ç†æ–‡ä»¶
    if 'processed_files' not in st.session_state:
        st.session_state.processed_files = set()


def init_qdrant():
    """åˆå§‹åŒ– Qdrant å®¢æˆ·ç«¯"""
    if not all([st.session_state.qdrant_api_key, st.session_state.qdrant_url]):
        return None

    try:
        vector_db = Qdrant(
            collection=COLLECTION_NAME,
            url=st.session_state.qdrant_url,
            api_key=st.session_state.qdrant_api_key,
            embedder=OpenAIEmbedder(
                id="text-embedding-3-small",
                api_key=st.session_state.openai_api_key,
                base_url=OPENAI_BASE_URL
            )
        )
        return vector_db
    except Exception as e:
        st.error(f"åˆå§‹åŒ– Qdrant å¤±è´¥: {e}")
        return None


def init_knowledge_base(vector_db):
    """åˆå§‹åŒ–çŸ¥è¯†åº“"""
    if not vector_db:
        return None

    try:
        knowledge_base = Knowledge(vector_db=vector_db)
        return knowledge_base
    except Exception as e:
        st.error(f"åˆå§‹åŒ–çŸ¥è¯†åº“å¤±è´¥: {e}")
        return None


def init_hybrid_search(vector_db):
    """
    åˆå§‹åŒ–æ··åˆæ£€ç´¢å¼•æ“

    é›†æˆ BM25 + å‘é‡æ£€ç´¢ + Reranker
    """
    if not vector_db:
        return None

    try:
        # åˆ›å»º BM25 ç´¢å¼•å™¨ï¼ˆéœ€è¦æ–‡æ¡£æ•°æ®ï¼‰
        bm25_indexer = BM25Indexer()

        # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä»æ•°æ®åº“åŠ è½½å·²ç´¢å¼•çš„æ–‡æ¡£
        # bm25_indexer.index_documents(documents)

        # åˆ›å»ºå‘é‡æ£€ç´¢å‡½æ•°
        async def vector_search(query: str, top_k: int):
            """å‘é‡æ£€ç´¢å‡½æ•°"""
            results = await vector_db.asearch(query, limit=top_k)
            # è½¬æ¢ä¸º SearchResult æ ¼å¼
            from src.models.search_models import SearchResult, RetrievalMethod
            return [
                SearchResult(
                    doc_id=r.get("id", ""),
                    score=r.get("score", 0),
                    retrieval_method=RetrievalMethod.VECTOR,
                    content=r.get("context", "")
                )
                for r in results
            ], 0.1

        # åˆ›å»ºæ··åˆæ£€ç´¢å¼•æ“
        engine = create_hybrid_search_engine(
            bm25_indexer=bm25_indexer,
            vector_search_func=vector_search,
            reranker_api_key=os.getenv("COHERE_API_KEY"),
            enable_cache=True
        )

        return engine

    except Exception as e:
        st.warning(f"æ··åˆæ£€ç´¢å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
        return None


def init_review_pipeline():
    """åˆå§‹åŒ–å®¡æŸ¥æµç¨‹"""
    try:
        pipeline = create_review_pipeline(
            openai_api_key=st.session_state.openai_api_key,
            model_name="gpt-4o",
            enabled_reviewers=["legal", "risk", "format", "business"],
            enable_parallel=True,
            max_rounds=2
        )
        return pipeline
    except Exception as e:
        st.warning(f"å®¡æŸ¥æµç¨‹åˆå§‹åŒ–å¤±è´¥: {e}")
        return None


def main():
    """ä¸»åº”ç”¨"""
    st.set_page_config(
        page_title="AI æ³•å¾‹æ–‡æ¡£åˆ†æåŠ©æ‰‹",
        page_icon="âš–ï¸",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    st.title("âš–ï¸ AI æ³•å¾‹æ–‡æ¡£åˆ†æåŠ©æ‰‹")
    st.markdown("---")

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    init_session_state()

    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("ğŸ”§ é…ç½®")

        # API Keys
        st.subheader("API å¯†é’¥")
        openai_key = st.text_input(
            "OpenAI API Key",
            type="password",
            value=st.session_state.openai_api_key or "",
            help="è¾“å…¥ OpenAI API å¯†é’¥"
        )

        qdrant_key = st.text_input(
            "Qdrant API Key (å¯é€‰)",
            type="password",
            value=st.session_state.qdrant_api_key or "",
            help="è¾“å…¥ Qdrant API å¯†é’¥ï¼ˆå¦‚éœ€è¦ï¼‰"
        )

        qdrant_url = st.text_input(
            "Qdrant URL",
            value=st.session_state.qdrant_url or "http://localhost:6333",
            help="Qdrant æœåŠ¡åœ°å€"
        )

        # ä¿å­˜é…ç½®
        if st.button("ä¿å­˜é…ç½®"):
            st.session_state.openai_api_key = openai_key
            st.session_state.qdrant_api_key = qdrant_key
            st.session_state.qdrant_url = qdrant_url
            st.success("é…ç½®å·²ä¿å­˜")

        st.markdown("---")

        # æ–°æ¶æ„å¼€å…³
        st.subheader("ğŸš€ æ–°æ¶æ„åŠŸèƒ½")
        enable_hybrid_search = st.checkbox(
            "å¯ç”¨æ··åˆæ£€ç´¢ (BM25 + å‘é‡)",
            value=True,
            help="å¯ç”¨æ··åˆæ£€ç´¢å’Œ Reranker"
        )

        enable_multi_agent = st.checkbox(
            "å¯ç”¨å¤šæ™ºèƒ½ä½“å®¡æŸ¥",
            value=True,
            help="å¯ç”¨å¹¶è¡Œå®¡æŸ¥å’Œä»²è£æœºåˆ¶"
        )

        enable_structured_output = st.checkbox(
            "å¯ç”¨ç»“æ„åŒ–è¾“å‡º",
            value=True,
            help="ç”Ÿæˆä¸‰å±‚ç»“æ„åŒ–æŠ¥å‘Š"
        )

        st.markdown("---")

        # ç³»ç»Ÿä¿¡æ¯
        st.subheader("ğŸ“Š ç³»ç»Ÿä¿¡æ¯")
        if st.session_state.vector_db:
            st.success("âœ… Qdrant å·²è¿æ¥")
        else:
            st.warning("âš ï¸ Qdrant æœªè¿æ¥")

        if enable_hybrid_search and st.session_state.hybrid_engine:
            st.success("âœ… æ··åˆæ£€ç´¢å·²å¯ç”¨")

        if enable_multi_agent and st.session_state.review_pipeline:
            st.success("âœ… å¤šæ™ºèƒ½ä½“å®¡æŸ¥å·²å¯ç”¨")

        # ç›‘æ§æŒ‡æ ‡
        if st.session_state.metrics.enabled:
            metrics_summary = st.session_state.metrics.get_metrics_summary()
            if metrics_summary.get("enabled"):
                st.metric("æ€»è¯·æ±‚æ•°", metrics_summary.get("retrieval_requests", 0))

    # ä¸»ç•Œé¢
    st.header("ğŸ“„ æ–‡æ¡£åˆ†æ")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "ä¸Šä¼ æ³•å¾‹æ–‡æ¡£",
        type=["pdf", "docx", "txt"],
        accept_multiple_files=True,
        help="æ”¯æŒ PDFã€DOCXã€TXT æ ¼å¼"
    )

    if not uploaded_files:
        st.info("ğŸ‘† è¯·ä¸Šä¼ æ–‡æ¡£å¼€å§‹åˆ†æ")
        st.markdown("""
        ### åŠŸèƒ½è¯´æ˜

        **ğŸ” æ··åˆæ£€ç´¢**
        - BM25 å…³é”®è¯æ£€ç´¢
        - å‘é‡è¯­ä¹‰æ£€ç´¢
        - RRF ç®—æ³•èåˆ
        - Cohere Reranker ç²¾æ’

        **ğŸ¤– å¤šæ™ºèƒ½ä½“å®¡æŸ¥**
        - Writer Agent è‰ç¨¿ç”Ÿæˆ
        - 4 ä¸ªä¸“ä¸š Reviewer å¹¶è¡Œå®¡æŸ¥
        - Arbitrator å†²çªä»²è£
        - Draft-Critique-Revise é—­ç¯

        **ğŸ“Š ç»“æ„åŒ–è¾“å‡º**
        - ä¸‰å±‚æŠ¥å‘Šç»“æ„
        - å¤šæ ¼å¼å¯¼å‡º (JSON/PDF/DOCX)
        - äº¤äº’å¼ UI å±•ç¤º
        """)
        return

    # åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶
    vector_db = init_qdrant()
    knowledge_base = init_knowledge_base(vector_db)

    if enable_hybrid_search:
        hybrid_engine = init_hybrid_search(vector_db)
        st.session_state.hybrid_engine = hybrid_engine

    if enable_multi_agent:
        review_pipeline = init_review_pipeline()
        st.session_state.review_pipeline = review_pipeline

    # åˆ†æé€‰é¡¹
    st.subheader("âš™ï¸ åˆ†æé€‰é¡¹")

    col1, col2, col3 = st.columns(3)

    with col1:
        analysis_type = st.selectbox(
            "åˆ†æç±»å‹",
            ["contract_review", "compliance_check", "risk_assessment"],
            format_func=lambda x: {
                "contract_review": "åˆåŒå®¡æŸ¥",
                "compliance_check": "åˆè§„æ£€æŸ¥",
                "risk_assessment": "é£é™©è¯„ä¼°"
            }[x]
        )

    with col2:
        export_formats = st.multiselect(
            "å¯¼å‡ºæ ¼å¼",
            ["json", "pdf", "docx"],
            default=["json", "md"]
        )

    with col3:
        use_new_architecture = st.checkbox(
            "ä½¿ç”¨æ–°æ¶æ„",
            value=True,
            help="ä½¿ç”¨æ··åˆæ£€ç´¢å’Œå¤šæ™ºèƒ½ä½“å®¡æŸ¥"
        )

    # åˆ†ææŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True):
        analyze_documents(
            uploaded_files,
            analysis_type,
            export_formats,
            use_new_architecture,
            enable_hybrid_search,
            enable_multi_agent
        )


def analyze_documents(
    files,
    analysis_type,
    export_formats,
    use_new_architecture,
    enable_hybrid_search,
    enable_multi_agent
):
    """åˆ†ææ–‡æ¡£"""
    st.info("ğŸ“Š æ­£åœ¨åˆ†ææ–‡æ¡£...")

    progress_bar = st.progress(0)
    status_text = st.empty()

    # Phase 1: æ–‡æ¡£è§£æ
    status_text.text("ğŸ“„ æ­£åœ¨è§£ææ–‡æ¡£...")
    progress_bar.progress(10)

    # Phase 2: æ£€ç´¢
    if enable_hybrid_search and st.session_state.hybrid_engine:
        status_text.text("ğŸ” æ­£åœ¨æ‰§è¡Œæ··åˆæ£€ç´¢...")
        progress_bar.progress(30)

    # Phase 3: Agent åˆ†æ
    if enable_multi_agent and st.session_state.review_pipeline:
        status_text.text("ğŸ¤– AI å›¢é˜Ÿæ­£åœ¨åˆ†æ...")
        progress_bar.progress(50)

    # Phase 4: æŠ¥å‘Šç”Ÿæˆ
    status_text.text("ğŸ“Š æ­£åœ¨ç”ŸæˆæŠ¥å‘Š...")
    progress_bar.progress(80)

    # å®Œæˆ
    progress_bar.progress(100)
    status_text.text("âœ… åˆ†æå®Œæˆ!")

    # æ˜¾ç¤ºç»“æœï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
    st.success("ğŸ‰ åˆ†æå®Œæˆï¼")

    if use_new_architecture:
        st.markdown("### ğŸ“Š åˆ†æç»“æœ")
        st.info("å®Œæ•´çš„ç»“æ„åŒ–æŠ¥å‘Šå°†åœ¨æ–°ç‰ˆæœ¬ä¸­å±•ç¤º")

        # å±•ç¤ºå ä½ç¬¦
        st.markdown("""
        **æ–°æ¶æ„åŠŸèƒ½**:
        - âœ… æ··åˆæ£€ç´¢ (BM25 + å‘é‡ + Reranker)
        - âœ… å¤šæ™ºèƒ½ä½“å®¡æŸ¥ (Writer + 4 Reviewers + Arbitrator)
        - âœ… ç»“æ„åŒ–è¾“å‡º (ä¸‰å±‚æŠ¥å‘Š)
        - âœ… å¤šæ ¼å¼å¯¼å‡º (JSON/PDF/DOCX)

        æŠ¥å‘ŠåŒ…å«:
        - ğŸ“Š æ‰§è¡Œæ‘˜è¦ï¼ˆé«˜ç®¡è§†è§’ï¼‰
        - ğŸ“‹ è¯¦ç»†åˆ†æï¼ˆå¾‹å¸ˆè§†è§’ï¼‰
        - ğŸ” è¯æ®æ¥æºï¼ˆå®¡è®¡è§†è§’ï¼‰
        """)


if __name__ == "__main__":
    main()
